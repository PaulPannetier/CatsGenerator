{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import neurolab as nl\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[ 0.6211502   0.91807437  0.91807437]\n",
      "   [ 0.75541973  0.98871326  0.98871326]\n",
      "   [ 0.87626237  1.1064447   1.1064447 ]\n",
      "   ...\n",
      "   [ 0.5942963   1.0004864   1.0004864 ]\n",
      "   [ 0.71513885  1.0004864   1.0004864 ]\n",
      "   [ 0.5540154   1.0004864   1.0004864 ]]\n",
      "\n",
      "  [[ 0.7957006   0.85920864  0.85920864]\n",
      "   [ 0.47345367  0.76502347  0.76502347]\n",
      "   [-1.3794663  -0.97740215 -0.97740215]\n",
      "   ...\n",
      "   [ 0.56744236  0.812116    0.812116  ]\n",
      "   [ 0.6211502   0.8827549   0.8827549 ]\n",
      "   [ 0.92997015  0.92984754  0.92984754]]\n",
      "\n",
      "  [[ 0.5942963   0.91807437  0.91807437]\n",
      "   [-0.6812646  -0.03555046 -0.03555046]\n",
      "   [ 0.41974583  0.87098175  0.87098175]\n",
      "   ...\n",
      "   [ 0.6614311   1.0475789   1.0475789 ]\n",
      "   [ 0.71513885  0.8827549   0.8827549 ]\n",
      "   [ 0.60772324  0.77679664  0.77679664]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.60772324  0.76502347  0.76502347]\n",
      "   [ 0.60772324  0.9651669   0.9651669 ]\n",
      "   [ 0.15120672  0.5413337   0.5413337 ]\n",
      "   ...\n",
      "   [ 0.6614311   1.0240327   1.0240327 ]\n",
      "   [ 0.80912757  1.0240327   1.0240327 ]\n",
      "   [ 0.8628354   1.0358058   1.0358058 ]]\n",
      "\n",
      "  [[ 0.6614311   0.8003429   0.8003429 ]\n",
      "   [-0.26502892 -0.01200417 -0.01200417]\n",
      "   [ 0.25862235  0.68261147  0.68261147]\n",
      "   ...\n",
      "   [ 0.5808693   1.0240327   1.0240327 ]\n",
      "   [ 0.7419928   0.91807437  0.91807437]\n",
      "   [ 0.68828493  1.1182178   1.1182178 ]]\n",
      "\n",
      "  [[ 0.84940845  0.94162065  0.94162065]\n",
      "   [ 0.37946495  0.83566236  0.83566236]\n",
      "   [-1.4331741  -0.883217   -0.883217  ]\n",
      "   ...\n",
      "   [ 0.5808693   0.9063012   0.9063012 ]\n",
      "   [ 0.6211502   0.77679664  0.77679664]\n",
      "   [ 0.9433971   0.94162065  0.94162065]]]\n",
      "\n",
      "\n",
      " [[[ 0.63457716  1.1064447   1.1064447 ]\n",
      "   [-0.22474806  0.41182908  0.41182908]\n",
      "   [-0.15761328  0.27055132  0.27055132]\n",
      "   ...\n",
      "   [ 0.8896893   1.0240327   1.0240327 ]\n",
      "   [ 0.6614311   0.8945281   0.8945281 ]\n",
      "   [ 0.80912757  0.9063012   0.9063012 ]]\n",
      "\n",
      "  [[ 0.8628354   0.78856975  0.78856975]\n",
      "   [-1.5003089  -0.8478975  -0.8478975 ]\n",
      "   [-1.8762637  -1.1186799  -1.1186799 ]\n",
      "   ...\n",
      "   [ 0.8628354   1.1064447   1.1064447 ]\n",
      "   [ 0.87626237  0.8474355   0.8474355 ]\n",
      "   [ 0.9433971   0.812116    0.812116  ]]\n",
      "\n",
      "  [[-1.8762637  -1.0833604  -1.0833604 ]\n",
      "   [-1.5942976  -1.1657724  -1.1657724 ]\n",
      "   [-1.3391855  -0.9420827  -0.9420827 ]\n",
      "   ...\n",
      "   [ 0.7017119   1.0475789   1.0475789 ]\n",
      "   [ 0.54058844  1.1182178   1.1182178 ]\n",
      "   [ 0.8225545   1.0240327   1.0240327 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-1.8628367  -1.365916   -1.365916  ]\n",
      "   [-1.8896906  -1.1893188  -1.1893188 ]\n",
      "   [-1.6211516  -1.0362679  -1.0362679 ]\n",
      "   ...\n",
      "   [ 0.8628354   0.94162065  0.94162065]\n",
      "   [ 0.92997015  0.8003429   0.8003429 ]\n",
      "   [ 0.5942963   0.78856975  0.78856975]]\n",
      "\n",
      "  [[-2.091095   -1.0598142  -1.0598142 ]\n",
      "   [-1.6748593  -1.0951335  -1.0951335 ]\n",
      "   [-1.446601   -0.83612436 -0.83612436]\n",
      "   ...\n",
      "   [ 0.8359815   1.1182178   1.1182178 ]\n",
      "   [ 0.67485803  0.8003429   0.8003429 ]\n",
      "   [ 0.84940845  0.8238892   0.8238892 ]]\n",
      "\n",
      "  [[ 0.84940845  1.0475789   1.0475789 ]\n",
      "   [-1.3123316  -0.75371236 -0.75371236]\n",
      "   [-2.1985106  -1.365916   -1.365916  ]\n",
      "   ...\n",
      "   [ 0.78227365  0.9769401   0.9769401 ]\n",
      "   [ 0.7688467   0.812116    0.812116  ]\n",
      "   [ 0.7688467   1.0593522   1.0593522 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.67485803  0.94162065  0.94162065]\n",
      "   [ 0.92997015  0.8474355   0.8474355 ]\n",
      "   [ 0.9433971   0.77679664  0.77679664]\n",
      "   ...\n",
      "   [ 0.75541973  1.1064447   1.1064447 ]\n",
      "   [ 0.7017119   0.812116    0.812116  ]\n",
      "   [ 0.68828493  1.0946716   1.0946716 ]]\n",
      "\n",
      "  [[ 0.6211502   1.0593522   1.0593522 ]\n",
      "   [ 0.71513885  0.9769401   0.9769401 ]\n",
      "   [ 0.9031163   1.0122595   1.0122595 ]\n",
      "   ...\n",
      "   [ 0.7419928   1.1182178   1.1182178 ]\n",
      "   [ 0.78227365  1.1064447   1.1064447 ]\n",
      "   [ 0.6211502   1.0711253   1.0711253 ]]\n",
      "\n",
      "  [[ 0.8896893   0.98871326  0.98871326]\n",
      "   [ 0.91654325  1.0946716   1.0946716 ]\n",
      "   [ 0.7285658   0.92984754  0.92984754]\n",
      "   ...\n",
      "   [ 0.8359815   0.87098175  0.87098175]\n",
      "   [ 0.7419928   0.78856975  0.78856975]\n",
      "   [ 0.78227365  0.77679664  0.77679664]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.8896893   1.0240327   1.0240327 ]\n",
      "   [ 0.6480041   1.1299909   1.1299909 ]\n",
      "   [ 0.7419928   0.78856975  0.78856975]\n",
      "   ...\n",
      "   [-1.2586237  -0.883217   -0.883217  ]\n",
      "   [ 0.80912757  0.78856975  0.78856975]\n",
      "   [-2.2387915  -1.613152   -1.613152  ]]\n",
      "\n",
      "  [[ 0.60772324  1.0593522   1.0593522 ]\n",
      "   [ 0.87626237  0.8827549   0.8827549 ]\n",
      "   [ 0.6211502   0.91807437  0.91807437]\n",
      "   ...\n",
      "   [ 0.5808693  -0.83612436 -0.83612436]\n",
      "   [-1.9568254  -1.6837909  -1.6837909 ]\n",
      "   [ 0.5540154   0.83566236  0.83566236]]\n",
      "\n",
      "  [[ 0.5942963   0.91807437  0.91807437]\n",
      "   [ 0.9031163   1.0240327   1.0240327 ]\n",
      "   [ 0.9031163   1.0122595   1.0122595 ]\n",
      "   ...\n",
      "   [ 0.7017119   1.0593522   1.0593522 ]\n",
      "   [ 0.8896893   1.0828984   1.0828984 ]\n",
      "   [ 0.68828493  1.0240327   1.0240327 ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 0.7688467   1.0240327   1.0240327 ]\n",
      "   [ 0.54058844  1.0828984   1.0828984 ]\n",
      "   [ 0.6480041   1.0122595   1.0122595 ]\n",
      "   ...\n",
      "   [ 0.6480041   0.8238892   0.8238892 ]\n",
      "   [ 0.9433971   1.0711253   1.0711253 ]\n",
      "   [ 0.6480041   0.8474355   0.8474355 ]]\n",
      "\n",
      "  [[ 0.60772324  1.1299909   1.1299909 ]\n",
      "   [ 0.56744236  0.92984754  0.92984754]\n",
      "   [ 0.71513885  0.8003429   0.8003429 ]\n",
      "   ...\n",
      "   [ 0.5808693   0.8827549   0.8827549 ]\n",
      "   [ 0.78227365  0.9651669   0.9651669 ]\n",
      "   [ 0.92997015  1.0475789   1.0475789 ]]\n",
      "\n",
      "  [[ 0.75541973  1.0828984   1.0828984 ]\n",
      "   [ 0.5540154   1.0946716   1.0946716 ]\n",
      "   [ 0.78227365  0.94162065  0.94162065]\n",
      "   ...\n",
      "   [ 0.7285658   0.83566236  0.83566236]\n",
      "   [ 0.7419928   0.9533938   0.9533938 ]\n",
      "   [ 0.5808693   1.0122595   1.0122595 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.8896893   0.8945281   0.8945281 ]\n",
      "   [-1.6748593  -1.5425131  -1.5425131 ]\n",
      "   [-1.6882863  -1.3070502  -1.3070502 ]\n",
      "   ...\n",
      "   [ 0.6480041   0.812116    0.812116  ]\n",
      "   [ 0.8896893   1.1299909   1.1299909 ]\n",
      "   [ 0.56744236  1.0122595   1.0122595 ]]\n",
      "\n",
      "  [[ 0.56744236  0.9063012   0.9063012 ]\n",
      "   [-0.5738489  -0.09441619 -0.09441619]\n",
      "   [-0.19789416 -0.10618933 -0.10618933]\n",
      "   ...\n",
      "   [ 0.80912757  0.83566236  0.83566236]\n",
      "   [ 0.8628354   0.83566236  0.83566236]\n",
      "   [ 0.8628354   1.0475789   1.0475789 ]]\n",
      "\n",
      "  [[ 0.6614311   0.94162065  0.94162065]\n",
      "   [ 0.91654325  0.87098175  0.87098175]\n",
      "   [ 0.7285658   0.85920864  0.85920864]\n",
      "   ...\n",
      "   [ 0.91654325  1.0004864   1.0004864 ]\n",
      "   [ 0.7688467   0.8238892   0.8238892 ]\n",
      "   [ 0.7957006   0.78856975  0.78856975]]]\n",
      "\n",
      "\n",
      " [[[ 0.8896893   0.9651669   0.9651669 ]\n",
      "   [ 0.60772324  0.8238892   0.8238892 ]\n",
      "   [ 0.56744236  0.85920864  0.85920864]\n",
      "   ...\n",
      "   [ 0.5808693   0.9769401   0.9769401 ]\n",
      "   [ 0.7688467   0.9533938   0.9533938 ]\n",
      "   [ 0.84940845  0.92984754  0.92984754]]\n",
      "\n",
      "  [[ 0.87626237  0.8238892   0.8238892 ]\n",
      "   [ 0.5942963   1.0358058   1.0358058 ]\n",
      "   [ 0.7688467   0.85920864  0.85920864]\n",
      "   ...\n",
      "   [ 0.7017119   0.8827549   0.8827549 ]\n",
      "   [ 0.71513885  0.8003429   0.8003429 ]\n",
      "   [ 0.71513885  1.0122595   1.0122595 ]]\n",
      "\n",
      "  [[ 0.8359815   0.9533938   0.9533938 ]\n",
      "   [ 0.44659975 -1.4954206  -1.4954206 ]\n",
      "   [ 0.7017119  -1.5071937  -1.5071937 ]\n",
      "   ...\n",
      "   [ 0.8896893   1.0240327   1.0240327 ]\n",
      "   [ 0.5808693   0.83566236  0.83566236]\n",
      "   [ 0.78227365  0.812116    0.812116  ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.6480041   1.1182178   1.1182178 ]\n",
      "   [ 0.71513885 -1.6484715  -1.6484715 ]\n",
      "   [ 0.41974583 -1.53074    -1.53074   ]\n",
      "   ...\n",
      "   [ 0.7957006  -1.2717308  -1.2717308 ]\n",
      "   [ 0.60772324 -1.3776891  -1.3776891 ]\n",
      "   [ 0.7957006   1.0004864   1.0004864 ]]\n",
      "\n",
      "  [[ 0.7285658   1.0004864   1.0004864 ]\n",
      "   [ 0.8225545   0.8827549   0.8827549 ]\n",
      "   [ 0.6614311   1.0593522   1.0593522 ]\n",
      "   ...\n",
      "   [ 0.48688063 -1.4365548  -1.4365548 ]\n",
      "   [ 0.8225545   0.729704    0.729704  ]\n",
      "   [ 0.6614311   0.9533938   0.9533938 ]]\n",
      "\n",
      "  [[ 0.92997015  0.8827549   0.8827549 ]\n",
      "   [ 0.6211502   1.1182178   1.1182178 ]\n",
      "   [ 0.71513885  0.8827549   0.8827549 ]\n",
      "   ...\n",
      "   [ 0.68828493  0.812116    0.812116  ]\n",
      "   [ 0.7688467   1.0358058   1.0358058 ]\n",
      "   [ 0.7957006   1.0711253   1.0711253 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.7017119   0.9769401   0.9769401 ]\n",
      "   [ 0.63457716  0.85920864  0.85920864]\n",
      "   [ 0.78227365  0.85920864  0.85920864]\n",
      "   ...\n",
      "   [ 0.92997015  1.0946716   1.0946716 ]\n",
      "   [ 0.71513885  0.9769401   0.9769401 ]\n",
      "   [ 0.68828493  0.91807437  0.91807437]]\n",
      "\n",
      "  [[ 0.9433971   0.85920864  0.85920864]\n",
      "   [ 0.5540154   0.78856975  0.78856975]\n",
      "   [ 0.8628354   0.85920864  0.85920864]\n",
      "   ...\n",
      "   [ 0.5942963   0.8003429   0.8003429 ]\n",
      "   [ 0.78227365  0.9651669   0.9651669 ]\n",
      "   [ 0.67485803  1.1064447   1.1064447 ]]\n",
      "\n",
      "  [[ 0.5942963   1.0593522   1.0593522 ]\n",
      "   [ 0.87626237  0.92984754  0.92984754]\n",
      "   [ 0.60772324  1.0593522   1.0593522 ]\n",
      "   ...\n",
      "   [-0.84238803 -1.0127215  -1.0127215 ]\n",
      "   [ 0.84940845  0.91807437  0.91807437]\n",
      "   [ 0.71513885  1.0358058   1.0358058 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.67485803  0.94162065  0.94162065]\n",
      "   [ 0.6614311   1.0475789   1.0475789 ]\n",
      "   [ 0.67485803  0.9063012   0.9063012 ]\n",
      "   ...\n",
      "   [ 0.84940845  0.92984754  0.92984754]\n",
      "   [ 0.80912757  0.9769401   0.9769401 ]\n",
      "   [ 0.63457716  0.812116    0.812116  ]]\n",
      "\n",
      "  [[ 0.7957006   1.1064447   1.1064447 ]\n",
      "   [ 0.87626237  1.0240327   1.0240327 ]\n",
      "   [ 0.7419928   1.0593522   1.0593522 ]\n",
      "   ...\n",
      "   [ 0.80912757  1.0240327   1.0240327 ]\n",
      "   [ 0.87626237  0.8945281   0.8945281 ]\n",
      "   [ 0.8896893   0.85920864  0.85920864]]\n",
      "\n",
      "  [[ 0.60772324  0.8827549   0.8827549 ]\n",
      "   [ 0.9031163   0.812116    0.812116  ]\n",
      "   [ 0.8359815   0.91807437  0.91807437]\n",
      "   ...\n",
      "   [ 0.7419928   0.8945281   0.8945281 ]\n",
      "   [ 0.5808693   1.0593522   1.0593522 ]\n",
      "   [ 0.60772324  0.9769401   0.9769401 ]]]], shape=(10, 32, 32, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#part using Keras\n",
    "\n",
    "noisyImgDir = 'Cats/noisy_32/88%'\n",
    "#dataset16x16 = keras.utils.image_dataset_from_directory(noisyImgDir, batch_size=116, image_size=(32, 32))\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, data, target):\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "\n",
    "def LoadDataSet(inputImagesDirectory:str, targetImagesDirectory:str,  nbMaxImages:int = -1):\n",
    "    files = [f for f in os.listdir(inputImagesDirectory) if os.path.isfile(inputImagesDirectory + \"/\" + f) and f.endswith(\".jpg\")]\n",
    "    if(nbMaxImages >= 1 and len(files) > nbMaxImages):\n",
    "        files = files[0:nbMaxImages]\n",
    "    images = [Image.open(inputImagesDirectory + imageName) for imageName in files]\n",
    "\n",
    "    tmpInputData = []# np.zeros(size= (len(files), images[0].size[0], images[0].size[1], 3))\n",
    "    for image in images:\n",
    "        tmp = []\n",
    "        for i in range(0, image.size[0]):\n",
    "            tmp.append([])\n",
    "            for j in range(image.size[1]):\n",
    "                pixel = image.getpixel((i, j))\n",
    "                tmp[i].append([pixel[0], pixel[2], pixel[2]])\n",
    "\n",
    "        tmpInputData.append(tmp)\n",
    "    inputData = np.array(tmpInputData)\n",
    "    tmpInputData = [] \n",
    "\n",
    "    files = [f for f in os.listdir(targetImagesDirectory) if os.path.isfile(targetImagesDirectory + \"/\" + f) and f.endswith(\".jpg\")]\n",
    "    if(nbMaxImages >= 1 and len(files) > nbMaxImages):\n",
    "        files = files[0:nbMaxImages]\n",
    "    images = [Image.open(inputImagesDirectory + imageName) for imageName in files]\n",
    "\n",
    "    tmpOutputData = []\n",
    "    for image in images:\n",
    "        tmp = []\n",
    "        for i in range(0, image.size[0]):\n",
    "            tmp.append([])\n",
    "            for j in range(image.size[1]):\n",
    "                pixel = image.getpixel((i, j))\n",
    "                tmp[i].append([pixel[0], pixel[2], pixel[2]])\n",
    "\n",
    "        tmpOutputData.append(tmp)\n",
    "    outputData = np.array(tmpOutputData)\n",
    "    tmpOutputData = [] \n",
    "\n",
    "    #normalizing the data\n",
    "    normalizer = Normalization(axis=-1)\n",
    "    normalizer.adapt(inputData)\n",
    "    inputData = normalizer(inputData)\n",
    "\n",
    "    normalizer = Normalization(axis=-1)\n",
    "    normalizer.adapt(outputData)\n",
    "    outputData = normalizer(outputData)\n",
    "\n",
    "    return Dataset(inputData, outputData)\n",
    "    \n",
    "dataSet = LoadDataSet(\"Cats/noisy_32/88%/\", \"Cats/pixellized_32/\", 10)\n",
    "\n",
    "#print(dataSet.data)\n",
    "#print(dataSet.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[125  98 111 214   2  35 125 187  99 235 201 154 125  98 111 214   2  35\n",
      " 125 187  99 235 201 154 125  98 111 214   2  35 125 187  99 235 201 154\n",
      " 125  98 111 214   2  35 125 187  99 235 201 154 125  98 111 214   2  35\n",
      " 125 187  99 235 201 154 125  98 111 214   2  35 125 187  99 235 201 154\n",
      " 125  98 111 214   2  35 125 187  99 235 201 154 125  98 111 214   2  35\n",
      " 125 187  99 235 201 154]\n"
     ]
    }
   ],
   "source": [
    "training_data = np.random.randint(0, 256, size=(5, 4, 4, 3)).astype(\"float32\")\n",
    "#print(training_data[0])*\n",
    "\n",
    "arr = [[[[125,98,111],[214,2,35],[125,187,99],[235,201,154]],[[125,98,111],[214,2,35],[125,187,99],[235,201,154]],[[125,98,111],[214,2,35],[125,187,99],[235,201,154]],[[125,98,111],[214,2,35],[125,187,99],[235,201,154]]]]\n",
    "arr2 = [[[[125,98,111],[214,2,35],[125,187,99],[235,201,154]],[[125,98,111],[214,2,35],[125,187,99],[235,201,154]],[[125,98,111],[214,2,35],[125,187,99],[235,201,154]],[[125,98,111],[214,2,35],[125,187,99],[235,201,154]]]]\n",
    "\n",
    "npArr = np.array(arr)\n",
    "npArr = np.append(npArr, arr2)\n",
    "print(npArr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb Input : 768\n",
      "nb Output : 768\n",
      "nb Layers : 10\n"
     ]
    }
   ],
   "source": [
    "#part using Neural network lib \n",
    "\n",
    "def CreateNeuralNetwork(nbInput:int, nbOutput:int, inputRange, nbLayers:int, nbNeuronsPerLayer):\n",
    "    inputDescription = []\n",
    "    for i in range(0, nbInputs):\n",
    "        inputDescription.append(inputRange[i])\n",
    "\n",
    "    layersDescription = []\n",
    "    for i in range(0, nbLayers - 1):\n",
    "        layersDescription.append(int(nbNeuronsPerLayers[i]))\n",
    "\n",
    "    layersDescription.append(nbOutputs)\n",
    "    return nl.net.newff(inputDescription, layersDescription)\n",
    "\n",
    "#neural network Stats\n",
    "imageSize = np.array([16, 16])\n",
    "nbInputs = imageSize[0] * imageSize[1] * 3\n",
    "nbOutputs = imageSize[0] * imageSize[1] * 3\n",
    "nbLayers = 10\n",
    "inputRange = [[0, 1] for i in range(0, nbInputs)]\n",
    "nbNeuronsPerLayers = np.ones(nbLayers) * 15\n",
    "\n",
    "net = CreateNeuralNetwork(nbInputs, nbOutputs, inputRange, nbLayers, nbNeuronsPerLayers)\n",
    "print(\"nb Input : \" + str(net.ci))\n",
    "print(\"nb Output : \" + str(net.co))\n",
    "print(\"nb Layers : \" + str(len(net.layers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotError(err):\n",
    "    plt.figure()\n",
    "    plt.plot(err)\n",
    "    plt.xlabel('Number of epochs')\n",
    "    plt.ylabel('Training error')\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Users\\Desktop\\im_a_folder\\Perso\\Prog\\C#\\CatsGenerator\\main.ipynb Cell 5\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Users/Desktop/im_a_folder/Perso/Prog/C%23/CatsGenerator/main.ipynb#W4sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m neural_net\u001b[39m.\u001b[39mtrainf \u001b[39m=\u001b[39m nl\u001b[39m.\u001b[39mtrain\u001b[39m.\u001b[39mtrain_gd\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Users/Desktop/im_a_folder/Perso/Prog/C%23/CatsGenerator/main.ipynb#W4sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m#train!\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Users/Desktop/im_a_folder/Perso/Prog/C%23/CatsGenerator/main.ipynb#W4sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m error \u001b[39m=\u001b[39m neural_net\u001b[39m.\u001b[39;49mtrain(data, labels, epochs \u001b[39m=\u001b[39;49m \u001b[39m1000\u001b[39;49m, show \u001b[39m=\u001b[39;49m \u001b[39m100\u001b[39;49m, goal \u001b[39m=\u001b[39;49m \u001b[39m0.01\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Users/Desktop/im_a_folder/Perso/Prog/C%23/CatsGenerator/main.ipynb#W4sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m output \u001b[39m=\u001b[39m neural_net\u001b[39m.\u001b[39msim(data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Users/Desktop/im_a_folder/Perso/Prog/C%23/CatsGenerator/main.ipynb#W4sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m y_pred \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mreshape(num_points)\n",
      "File \u001b[1;32mc:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\neurolab\\core.py:165\u001b[0m, in \u001b[0;36mNet.train\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    160\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[39m    Train network\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[39m    see net.trainf.__doc__\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \n\u001b[0;32m    164\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 165\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainf(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\neurolab\\core.py:349\u001b[0m, in \u001b[0;36mTrainer.__call__\u001b[1;34m(self, net, input, target, **kwargs)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merror \u001b[39m=\u001b[39m []\n\u001b[0;32m    348\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 349\u001b[0m     train(net, \u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    350\u001b[0m \u001b[39mexcept\u001b[39;00m TrainStop \u001b[39mas\u001b[39;00m msg:\n\u001b[0;32m    351\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams[\u001b[39m'\u001b[39m\u001b[39mshow\u001b[39m\u001b[39m'\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\neurolab\\train\\gd.py:45\u001b[0m, in \u001b[0;36mTrainGD.__call__\u001b[1;34m(self, net, input, target)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madapt:\n\u001b[0;32m     44\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m---> 45\u001b[0m         g, output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcalc(net, \u001b[39minput\u001b[39;49m, target)\n\u001b[0;32m     46\u001b[0m         \u001b[39m# regularization grad\u001b[39;00m\n\u001b[0;32m     47\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrr \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\neurolab\\train\\gd.py:71\u001b[0m, in \u001b[0;36mTrainGD.calc\u001b[1;34m(self, net, input, target)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcalc\u001b[39m(\u001b[39mself\u001b[39m, net, \u001b[39minput\u001b[39m, target):\n\u001b[1;32m---> 71\u001b[0m     g1, g2, output \u001b[39m=\u001b[39m tool\u001b[39m.\u001b[39;49mff_grad(net, \u001b[39minput\u001b[39;49m, target)\n\u001b[0;32m     72\u001b[0m     \u001b[39mreturn\u001b[39;00m g1, output\n",
      "File \u001b[1;32mc:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\neurolab\\tool.py:235\u001b[0m, in \u001b[0;36mff_grad\u001b[1;34m(net, input, target)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[39mfor\u001b[39;00m inp, tar \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39minput\u001b[39m, target):\n\u001b[0;32m    234\u001b[0m     out \u001b[39m=\u001b[39m net\u001b[39m.\u001b[39mstep(inp)\n\u001b[1;32m--> 235\u001b[0m     ff_grad_step(net, out, tar, grad)\n\u001b[0;32m    236\u001b[0m     output\u001b[39m.\u001b[39mappend(out)\n\u001b[0;32m    237\u001b[0m \u001b[39mreturn\u001b[39;00m grad, grad_flat, np\u001b[39m.\u001b[39mrow_stack(output)\n",
      "File \u001b[1;32mc:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\neurolab\\tool.py:187\u001b[0m, in \u001b[0;36mff_grad_step\u001b[1;34m(net, out, tar, grad)\u001b[0m\n\u001b[0;32m    184\u001b[0m layer \u001b[39m=\u001b[39m net\u001b[39m.\u001b[39mlayers[ln]\n\u001b[0;32m    185\u001b[0m \u001b[39mnext\u001b[39m \u001b[39m=\u001b[39m ln \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> 187\u001b[0m dS \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49msum(net\u001b[39m.\u001b[39;49mlayers[\u001b[39mnext\u001b[39;49m]\u001b[39m.\u001b[39;49mnp[\u001b[39m'\u001b[39;49m\u001b[39mw\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m*\u001b[39;49m delt[\u001b[39mnext\u001b[39;49m], axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[0;32m    188\u001b[0m delt[ln] \u001b[39m=\u001b[39m dS \u001b[39m*\u001b[39m layer\u001b[39m.\u001b[39mtransf\u001b[39m.\u001b[39mderiv(layer\u001b[39m.\u001b[39ms, layer\u001b[39m.\u001b[39mout)\n\u001b[0;32m    189\u001b[0m delt[ln]\u001b[39m.\u001b[39mshape \u001b[39m=\u001b[39m delt[ln]\u001b[39m.\u001b[39msize, \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32m<__array_function__ internals>:179\u001b[0m, in \u001b[0;36msum\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#test\n",
    "#net pour trouver l'équation 2*x² + 8\n",
    "\n",
    "min_val = -30\n",
    "max_val = 30\n",
    "num_points = 150\n",
    "x = np.linspace(min_val, max_val, num_points)\n",
    "y = 2 * np.square(x) + 8\n",
    "y /= np.linalg.norm(y)\n",
    "\n",
    "data = x.reshape(num_points, 1)\n",
    "labels = y.reshape(num_points, 1)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(data, labels)\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "plt.title('Data-points')\n",
    "\n",
    "#Now, build the neural network having two hidden layers with neurolab with ten neurons in the first hidden layer, six in the second hidden layer and one in the output layer.\n",
    "neural_net = nl.net.newff([[min_val, max_val]], [10, 6, 1])\n",
    "\n",
    "#using the gradient training algorithm −\n",
    "neural_net.trainf = nl.train.train_gd\n",
    "\n",
    "#train!\n",
    "error = neural_net.train(data, labels, epochs = 1000, show = 100, goal = 0.01)\n",
    "\n",
    "output = neural_net.sim(data)\n",
    "y_pred = output.reshape(num_points)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(error)\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Training error progress')\n",
    "\n",
    "\n",
    "x_dense = np.linspace(min_val, max_val, num_points * 2)\n",
    "y_dense_pred = neural_net.sim(x_dense.reshape(x_dense.size,1)).reshape(x_dense.size)\n",
    "plt.figure()\n",
    "plt.plot(x_dense, y_dense_pred, '-', x, y, '.', x, y_pred, 'p')\n",
    "plt.title('Actual vs predicted')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 4.94 GiB for an array with shape (25743, 25743) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32md:\\Users\\Desktop\\im_a_folder\\Perso\\Prog\\C#\\CatsGenerator\\main.ipynb Cell 6\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Users/Desktop/im_a_folder/Perso/Prog/C%23/CatsGenerator/main.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m net\u001b[39m.\u001b[39mtrain(dataSet\u001b[39m.\u001b[39mdata, dataSet\u001b[39m.\u001b[39mtarget,epochs \u001b[39m=\u001b[39m \u001b[39m500\u001b[39m, show \u001b[39m=\u001b[39m \u001b[39m50\u001b[39m, goal \u001b[39m=\u001b[39m \u001b[39m0.01\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Users/Desktop/im_a_folder/Perso/Prog/C%23/CatsGenerator/main.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Users/Desktop/im_a_folder/Perso/Prog/C%23/CatsGenerator/main.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mdataSet = LoadDataSet(\"Cats/noisy/88%/\", \"Cats/pixellized/\", 10)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Users/Desktop/im_a_folder/Perso/Prog/C%23/CatsGenerator/main.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Users/Desktop/im_a_folder/Perso/Prog/C%23/CatsGenerator/main.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m    dataSet.target[i] = dataSet.target[i][0 : nbEntriesAndOutput]\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Users/Desktop/im_a_folder/Perso/Prog/C%23/CatsGenerator/main.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Users/Desktop/im_a_folder/Perso/Prog/C%23/CatsGenerator/main.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m err \u001b[39m=\u001b[39m Train(dataSet)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Users/Desktop/im_a_folder/Perso/Prog/C%23/CatsGenerator/main.ipynb#W5sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m PlotError(err)\n",
      "\u001b[1;32md:\\Users\\Desktop\\im_a_folder\\Perso\\Prog\\C#\\CatsGenerator\\main.ipynb Cell 6\u001b[0m in \u001b[0;36mTrain\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Users/Desktop/im_a_folder/Perso/Prog/C%23/CatsGenerator/main.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mTrain\u001b[39m(dataset):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Users/Desktop/im_a_folder/Perso/Prog/C%23/CatsGenerator/main.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m net\u001b[39m.\u001b[39;49mtrain(dataSet\u001b[39m.\u001b[39;49mdata, dataSet\u001b[39m.\u001b[39;49mtarget,epochs \u001b[39m=\u001b[39;49m \u001b[39m500\u001b[39;49m, show \u001b[39m=\u001b[39;49m \u001b[39m50\u001b[39;49m, goal \u001b[39m=\u001b[39;49m \u001b[39m0.01\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\neurolab\\core.py:165\u001b[0m, in \u001b[0;36mNet.train\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    160\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[39m    Train network\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[39m    see net.trainf.__doc__\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \n\u001b[0;32m    164\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 165\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainf(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\neurolab\\core.py:349\u001b[0m, in \u001b[0;36mTrainer.__call__\u001b[1;34m(self, net, input, target, **kwargs)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merror \u001b[39m=\u001b[39m []\n\u001b[0;32m    348\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 349\u001b[0m     train(net, \u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    350\u001b[0m \u001b[39mexcept\u001b[39;00m TrainStop \u001b[39mas\u001b[39;00m msg:\n\u001b[0;32m    351\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams[\u001b[39m'\u001b[39m\u001b[39mshow\u001b[39m\u001b[39m'\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\neurolab\\train\\spo.py:78\u001b[0m, in \u001b[0;36mTrainBFGS.__call__\u001b[1;34m(self, net, input, target)\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs[\u001b[39m'\u001b[39m\u001b[39mdisp\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     76\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs[\u001b[39m'\u001b[39m\u001b[39mmaxiter\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepochs\n\u001b[1;32m---> 78\u001b[0m x \u001b[39m=\u001b[39m fmin_bfgs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfcn, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx\u001b[39m.\u001b[39mcopy(), fprime\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrad, callback\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep,\n\u001b[0;32m     79\u001b[0m               \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs)\n\u001b[0;32m     80\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx[:] \u001b[39m=\u001b[39m x\n",
      "File \u001b[1;32mc:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\optimize\\_optimize.py:1238\u001b[0m, in \u001b[0;36mfmin_bfgs\u001b[1;34m(f, x0, fprime, args, gtol, norm, epsilon, maxiter, full_output, disp, retall, callback)\u001b[0m\n\u001b[0;32m   1132\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m \u001b[39mMinimize a function using the BFGS algorithm.\u001b[39;00m\n\u001b[0;32m   1134\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1229\u001b[0m \n\u001b[0;32m   1230\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1231\u001b[0m opts \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mgtol\u001b[39m\u001b[39m'\u001b[39m: gtol,\n\u001b[0;32m   1232\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mnorm\u001b[39m\u001b[39m'\u001b[39m: norm,\n\u001b[0;32m   1233\u001b[0m         \u001b[39m'\u001b[39m\u001b[39meps\u001b[39m\u001b[39m'\u001b[39m: epsilon,\n\u001b[0;32m   1234\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mdisp\u001b[39m\u001b[39m'\u001b[39m: disp,\n\u001b[0;32m   1235\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mmaxiter\u001b[39m\u001b[39m'\u001b[39m: maxiter,\n\u001b[0;32m   1236\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mreturn_all\u001b[39m\u001b[39m'\u001b[39m: retall}\n\u001b[1;32m-> 1238\u001b[0m res \u001b[39m=\u001b[39m _minimize_bfgs(f, x0, args, fprime, callback\u001b[39m=\u001b[39mcallback, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mopts)\n\u001b[0;32m   1240\u001b[0m \u001b[39mif\u001b[39;00m full_output:\n\u001b[0;32m   1241\u001b[0m     retlist \u001b[39m=\u001b[39m (res[\u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m], res[\u001b[39m'\u001b[39m\u001b[39mfun\u001b[39m\u001b[39m'\u001b[39m], res[\u001b[39m'\u001b[39m\u001b[39mjac\u001b[39m\u001b[39m'\u001b[39m], res[\u001b[39m'\u001b[39m\u001b[39mhess_inv\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m   1242\u001b[0m                res[\u001b[39m'\u001b[39m\u001b[39mnfev\u001b[39m\u001b[39m'\u001b[39m], res[\u001b[39m'\u001b[39m\u001b[39mnjev\u001b[39m\u001b[39m'\u001b[39m], res[\u001b[39m'\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\optimize\\_optimize.py:1363\u001b[0m, in \u001b[0;36m_minimize_bfgs\u001b[1;34m(fun, x0, args, jac, callback, gtol, norm, eps, maxiter, disp, return_all, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m   1361\u001b[0m     A1 \u001b[39m=\u001b[39m I \u001b[39m-\u001b[39m sk[:, np\u001b[39m.\u001b[39mnewaxis] \u001b[39m*\u001b[39m yk[np\u001b[39m.\u001b[39mnewaxis, :] \u001b[39m*\u001b[39m rhok\n\u001b[0;32m   1362\u001b[0m     A2 \u001b[39m=\u001b[39m I \u001b[39m-\u001b[39m yk[:, np\u001b[39m.\u001b[39mnewaxis] \u001b[39m*\u001b[39m sk[np\u001b[39m.\u001b[39mnewaxis, :] \u001b[39m*\u001b[39m rhok\n\u001b[1;32m-> 1363\u001b[0m     Hk \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(A1, np\u001b[39m.\u001b[39;49mdot(Hk, A2)) \u001b[39m+\u001b[39m (rhok \u001b[39m*\u001b[39m sk[:, np\u001b[39m.\u001b[39mnewaxis] \u001b[39m*\u001b[39m\n\u001b[0;32m   1364\u001b[0m                                              sk[np\u001b[39m.\u001b[39mnewaxis, :])\n\u001b[0;32m   1366\u001b[0m fval \u001b[39m=\u001b[39m old_fval\n\u001b[0;32m   1368\u001b[0m \u001b[39mif\u001b[39;00m warnflag \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 4.94 GiB for an array with shape (25743, 25743) and data type float64"
     ]
    }
   ],
   "source": [
    "def Train(dataset):\n",
    "    return net.train(dataSet.data, dataSet.target,epochs = 500, show = 50, goal = 0.01)\n",
    "\n",
    "\"\"\"\n",
    "dataSet = LoadDataSet(\"Cats/noisy/88%/\", \"Cats/pixellized/\", 10)\n",
    "\n",
    "for i in range(0, len(dataSet.data)):\n",
    "    dataSet.data[i] = dataSet.data[i][0 : nbEntriesAndOutput]\n",
    "    dataSet.target[i] = dataSet.target[i][0 : nbEntriesAndOutput]\n",
    "\"\"\"\n",
    "err = Train(dataSet)\n",
    "\n",
    "PlotError(err)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9be826744cc5714b462ad0c8de88bfa6f016a48973c6317b9546595d1685cabb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
